### Dynamic Parallelism
- Useful in scenarios involving nested parallelism.
```for i ...
        for j = f(i) ...
            work(j)```
    - Algorithms using hierarchical data structures 
    - Algorithms using recursion where each level of recursion has parallelism
    - Algorithms where work naturally splits into independent batches, and each batch involves parallel processing
.Not all nested parallel loops need DP.
```

## DP Computation
- Parent kernel is associated with a parent grid.
- Child kernels are associated with child grids. 
- Parent and child kernels may execute asynchronously.
- A parent grid is not complete unless all its children have completed.

## DP Memory
- Parent and children share global and constant memory.
- But they have distinct local and shared memories.
- All global memory operations in the parent before child's launch are visible to the child.
- All global memory operations of the child are visible to the parent after the parent synchronizes on the child's completion.

```
_global___ void child_launch(int *data) { 
    data[threadldx.x]= data[threadldx.x]+ 1;
}
_global__ void parent_launch(int *data) { 
    data[threadldx.x] = threadldx.x;
    __syncthreads();
    if (threadldx.x == 0){
        child_launch<<< 1, 256 >>>(data); 
        cudaDeviceSynchronize();
        }
        __syncthreads();
}
void host_launch(int *ata){
    parent_launch<<< 1, 256 >>>(data); 
    cudaDeviceSynchronize();
}

```

## Local or Shared Memory
- It is illegal to pass pointer to shared or local memory.
```
int x array[10]: //Creates x_array in parent's local memory 
child_launch<<< 1, 1 >>>(x_array);
    
```
- Argument passed should be pointers to global memory: cudaMalloc, new or global _device__.
```
// Correct access
device__int value;	//Kernel can be called	
device__void x(){	//from a device function.	
    vaiue =5:
    child<<< 1, 1 >>>(&vaiue);
}
```

## DP Synchronization
- Grids launched into the same stream are executed in-order.
- Events can be used to create dependencies across streams.
- Streams and events created within a grid exist within thread block scope. They have undefined behavior when used outside the thread-block where they are created.
    - Thus, all threads of a thread-block by default launch kernels into the same default stream.

## DP Overheads
- To launch a kernel, CUDA driver and runtime parse parameters, buffer their values, and issue kernel dispatch.
- Kernels waiting to execute are inserted in a pending buffer, modeled as fixed-sized + variable-sized pools. The latter has higher management overheads.
- If parent explicitly synchronizes with the child, to free resources for the execution of the children, parent kernels may be swapped to global memory.