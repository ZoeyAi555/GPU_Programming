**Kernel 1**
1. Preprocessing
2. Global barrier (for this grid)
3. If (another kernel)
    Work= N/2
4. Else
    Work=N
5. Process work

**Kernel 2**
1. Work = N/2
2. Process work

## Stream Synchronization
- ```CudaDeviceSynchronize()``` waits for all commands from all streams.
- ```CudaStreamSynchronize(s)``` waits for all commands from a particular stream s.
    - For non-blocking check, use ```cudaStreamQuery(s)```.
- Commands from different streams cannot run concurrently if they are separated by:
    - Page-locked host memory allocation 
    - Device memory allocation 
    - Device memset 
    - Memcpy on the same device memory
    - CUDA commands to the default stream
    - Switch between L1/shared memory configurations