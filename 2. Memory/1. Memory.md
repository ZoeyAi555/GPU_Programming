
## Bandwidth ##
Big data bus rather than fast data bus
Parallel data transfer
Improve bandwidth:
- share/resue data
- data compression
- recompute than store + fetch

## Lantency ##
I/O

## Locality ##
### Spatial 空间上的 ###
a[i] be accessed -> a[i+k] also be accessed
``` for (i=0;i<N;i++) a[i] = 0; ```

### Temporal 时间上的 ###
a[i] be accessed now -> a[i] be accessed soon again
``` a[i] = i; a[i] += N; b[i] = a[i]*a[i] ```

## Memory Coalescing凝集 ##
If warp threads access words from the same block of 32 words, their memory requests are clubbed into one.
Without coalescing, each load/store would require one memory cycle

Degree of Coalescing: 33 - # memory transactions required for a wrap to execute an instruction
a[threadIdx.x] DoC 32
a[rand()] DoC 1 worst

## AoS vs SoA 
**AoS**: a thread accesses an attribute of a node, 
it also access an attricute of a node, 
it also access other attributes of the same node.
Better locality on CPU
(Array of Structures)：在这种方式中，每个节点的所有属性都存储在一起。这意味着当一个线程访问一个节点的一个属性时，它也可能访问该节点的其他属性。这种方式在CPU上有更好的局部性，因为CPU缓存通常会加载整个结构，即使只访问了其中的一个属性。

```
struct node {
    int a;
    double b;
    char c;
};
struct node allnodes[N];
```

**SoA**:a thread accesses an attribute of a node, 
its neighboring thread accesses the same attribute of the next node 
Better coalesting on GPU
(Structure of Arrays)：在这种方式中，每个属性都存储在一个单独的数组中。这意味着当一个线程访问一个节点的一个属性时，它的邻居线程会访问下一个节点的同一属性。这种方式在GPU上有更好的合并性，因为GPU更善于同时访问连续的内存位置。

```
struct node{
    int alla[N];
    double allb[N];
    char allc[N];
};
```





